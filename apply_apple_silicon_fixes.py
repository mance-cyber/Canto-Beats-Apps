#!/usr/bin/env python3
"""
Apple Silicon å„ªåŒ– - å¿«é€Ÿä¿®å¾©è…³æœ¬

è‡ªå‹•æ‡‰ç”¨é—œéµå„ªåŒ–åˆ° Canto-Beats ä»£ç¢¼åº«ã€‚
åŸ·è¡Œå‰è«‹å‚™ä»½ä»£ç¢¼ï¼

ä½¿ç”¨æ–¹æ³•:
    python apply_apple_silicon_fixes.py --dry-run  # é è¦½è®Šæ›´
    python apply_apple_silicon_fixes.py --apply    # æ‡‰ç”¨è®Šæ›´
"""

import sys
import argparse
from pathlib import Path
from typing import List, Tuple

# ==================== é…ç½® ====================
PROJECT_ROOT = Path(__file__).parent
BACKUP_DIR = PROJECT_ROOT / "backups" / "pre_apple_silicon_optimization"

# ==================== ä¿®å¾©å®šç¾© ====================
FIXES = [
    {
        "name": "ä¿®å¾© MPS VRAM æª¢æ¸¬",
        "file": "src/core/hardware_detector.py",
        "line_range": (153, 170),
        "old_code": '''        # 1. Check Apple Silicon MPS (Metal Performance Shaders)
        try:
            if torch.backends.mps.is_available() and torch.backends.mps.is_built():
                logger.info("Apple MPS (Metal) detected - Apple Silicon GPU")
                # MPS shares system memory, no dedicated VRAM concept
                # Return 0 to trigger appropriate tier selection
                return "mps", 0.0
        except Exception as e:
            logger.debug(f"MPS check failed: {e}")''',
        "new_code": '''        # 1. Check Apple Silicon MPS (Metal Performance Shaders)
        try:
            if torch.backends.mps.is_available() and torch.backends.mps.is_built():
                logger.info("Apple MPS (Metal) detected - Apple Silicon GPU")
                
                # MPS shares unified memory - calculate effective VRAM (70% of system RAM)
                try:
                    import psutil
                    system_ram_gb = psutil.virtual_memory().total / (1024 ** 3)
                    effective_vram = system_ram_gb * 0.7
                    logger.info(f"MPS effective VRAM: {effective_vram:.1f} GB (70% of {system_ram_gb:.1f} GB system RAM)")
                    return "mps", effective_vram
                except ImportError:
                    logger.warning("psutil not available, assuming 16GB effective VRAM")
                    return "mps", 16.0  # Conservative estimate for M1/M2 Macs
        except Exception as e:
            logger.debug(f"MPS check failed: {e}")''',
    },
    {
        "name": "å•Ÿç”¨ LLM MPS è¨­å‚™æ˜ å°„",
        "file": "src/models/qwen_llm.py",
        "line_range": (98, 102),
        "old_code": '''            # Determine quantization config based on VRAM
            model_a_kwargs = {
                "device_map": "auto" if device == "cuda" else "cpu",
                "trust_remote_code": True,
            }''',
        "new_code": '''            # Determine device map (support MPS)
            def get_device_map(device: str):
                if device == "cuda":
                    return "auto"
                elif device == "mps":
                    return "mps"  # PyTorch 2.0+ native MPS support
                else:
                    return "cpu"
            
            model_a_kwargs = {
                "device_map": get_device_map(device),
                "trust_remote_code": True,
                "torch_dtype": torch.float16 if device in ["cuda", "mps"] else torch.float32,
            }''',
    },
]

# ==================== å·¥å…·å‡½æ•¸ ====================
def backup_file(file_path: Path):
    """å‚™ä»½æ–‡ä»¶åˆ° backups ç›®éŒ„"""
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    backup_path = BACKUP_DIR / file_path.name
    backup_path.write_text(file_path.read_text())
    print(f"  âœ… å·²å‚™ä»½: {backup_path}")

def apply_fix(fix: dict, dry_run: bool = True) -> bool:
    """æ‡‰ç”¨å–®å€‹ä¿®å¾©"""
    file_path = PROJECT_ROOT / fix["file"]
    
    if not file_path.exists():
        print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    content = file_path.read_text()
    
    if fix["old_code"] not in content:
        print(f"  âš ï¸  æœªæ‰¾åˆ°ç›®æ¨™ä»£ç¢¼ï¼Œå¯èƒ½å·²ä¿®å¾©æˆ–ä»£ç¢¼å·²è®Šæ›´")
        return False
    
    if dry_run:
        print(f"  ğŸ“ [é è¦½] å°‡æ›¿æ› {fix['line_range'][1] - fix['line_range'][0] + 1} è¡Œä»£ç¢¼")
        return True
    
    # å‚™ä»½åŸæ–‡ä»¶
    backup_file(file_path)
    
    # æ‡‰ç”¨ä¿®å¾©
    new_content = content.replace(fix["old_code"], fix["new_code"])
    file_path.write_text(new_content)
    
    print(f"  âœ… å·²æ‡‰ç”¨ä¿®å¾©")
    return True

# ==================== ä¸»ç¨‹åº ====================
def main():
    parser = argparse.ArgumentParser(description="Apple Silicon å„ªåŒ–å¿«é€Ÿä¿®å¾©")
    parser.add_argument("--dry-run", action="store_true", help="é è¦½è®Šæ›´ï¼ˆä¸å¯¦éš›ä¿®æ”¹æ–‡ä»¶ï¼‰")
    parser.add_argument("--apply", action="store_true", help="æ‡‰ç”¨è®Šæ›´")
    args = parser.parse_args()
    
    if not args.dry_run and not args.apply:
        parser.print_help()
        sys.exit(1)
    
    mode = "é è¦½æ¨¡å¼" if args.dry_run else "æ‡‰ç”¨æ¨¡å¼"
    print(f"\n{'='*60}")
    print(f"Apple Silicon å„ªåŒ– - {mode}")
    print(f"{'='*60}\n")
    
    success_count = 0
    for i, fix in enumerate(FIXES, 1):
        print(f"[{i}/{len(FIXES)}] {fix['name']}")
        print(f"  æ–‡ä»¶: {fix['file']}")
        
        if apply_fix(fix, dry_run=args.dry_run):
            success_count += 1
        print()
    
    print(f"{'='*60}")
    print(f"å®Œæˆ: {success_count}/{len(FIXES)} å€‹ä¿®å¾©æˆåŠŸ")
    
    if args.dry_run:
        print("\nğŸ’¡ ä½¿ç”¨ --apply åƒæ•¸ä¾†å¯¦éš›æ‡‰ç”¨è®Šæ›´")
    else:
        print(f"\nâœ… å‚™ä»½ä½ç½®: {BACKUP_DIR}")
        print("âš ï¸  è«‹é‹è¡Œæ¸¬è©¦ç¢ºä¿ä¸€åˆ‡æ­£å¸¸ï¼")
    print(f"{'='*60}\n")

if __name__ == "__main__":
    main()

