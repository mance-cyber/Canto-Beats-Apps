#!/usr/bin/env python3
"""æ¸¬è©¦é¦–æ¬¡ä¸‹è¼‰è§¸ç™¼é‚è¼¯"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_download_trigger():
    """æ¸¬è©¦ä¸‹è¼‰å°è©±æ¡†æ˜¯å¦æœƒåœ¨é¦–æ¬¡ä½¿ç”¨æ™‚è§¸ç™¼"""
    
    print("=" * 60)
    print("æ¸¬è©¦ï¼šé¦–æ¬¡ä¸‹è¼‰è§¸ç™¼é‚è¼¯")
    print("=" * 60)
    
    # 1. æª¢æŸ¥ MLX Whisper æ¨¡å‹æ˜¯å¦å·²ç·©å­˜
    print("\n1. æª¢æŸ¥ MLX Whisper æ¨¡å‹ç·©å­˜...")
    try:
        from huggingface_hub import try_to_load_from_cache
        
        model_path = "mlx-community/whisper-large-v3-mlx"
        cache_path = try_to_load_from_cache(model_path, "config.json")
        
        if cache_path is None or cache_path == "_CACHED_":
            print(f"   âŒ æ¨¡å‹æœªç·©å­˜: {model_path}")
            print(f"   âœ… é¦–æ¬¡è½‰å¯«æ™‚ã€Œæ‡‰è©²ã€å½ˆå‡ºä¸‹è¼‰å°è©±æ¡†")
        else:
            print(f"   âœ… æ¨¡å‹å·²ç·©å­˜: {cache_path}")
            print(f"   âš ï¸  é¦–æ¬¡è½‰å¯«æ™‚ã€Œä¸æœƒã€å½ˆå‡ºä¸‹è¼‰å°è©±æ¡†")
    except Exception as e:
        print(f"   âŒ æª¢æŸ¥å¤±æ•—: {e}")
    
    # 2. æª¢æŸ¥ Qwen LLM æ¨¡å‹æ˜¯å¦å·²ç·©å­˜
    print("\n2. æª¢æŸ¥ Qwen LLM æ¨¡å‹ç·©å­˜...")
    try:
        from core.config import Config
        config = Config()
        
        llm_cached = config.is_model_cached("llm")
        
        if llm_cached:
            print(f"   âœ… Qwen æ¨¡å‹å·²ç·©å­˜")
            print(f"   âš ï¸  æ›¸é¢èªè½‰æ›æ™‚ã€Œä¸æœƒã€å½ˆå‡ºä¸‹è¼‰å°è©±æ¡†")
        else:
            print(f"   âŒ Qwen æ¨¡å‹æœªç·©å­˜")
            print(f"   âœ… æ›¸é¢èªè½‰æ›æ™‚ã€Œæ‡‰è©²ã€å½ˆå‡ºä¸‹è¼‰å°è©±æ¡†")
    except Exception as e:
        print(f"   âŒ æª¢æŸ¥å¤±æ•—: {e}")
    
    # 3. æ¸¬è©¦ä¸‹è¼‰å°è©±æ¡†çµ„ä»¶
    print("\n3. æ¸¬è©¦ä¸‹è¼‰å°è©±æ¡†çµ„ä»¶...")
    try:
        from ui.download_dialog import ModelDownloadDialog, MLXWhisperDownloadWorker
        print(f"   âœ… ModelDownloadDialog å¯å°å…¥")
        print(f"   âœ… MLXWhisperDownloadWorker å¯å°å…¥")
    except Exception as e:
        print(f"   âŒ å°å…¥å¤±æ•—: {e}")
    
    # 4. æª¢æŸ¥ pipeline ä¸­çš„ä¸‹è¼‰é‚è¼¯
    print("\n4. æª¢æŸ¥ pipeline ä¸‹è¼‰é‚è¼¯...")
    try:
        with open("src/pipeline/subtitle_pipeline_v2.py", "r") as f:
            content = f.read()
            
        if "ModelDownloadDialog" in content:
            print(f"   âœ… Pipeline åŒ…å«ä¸‹è¼‰å°è©±æ¡†é‚è¼¯")
        else:
            print(f"   âŒ Pipeline ç¼ºå°‘ä¸‹è¼‰å°è©±æ¡†é‚è¼¯")
            
        if "MLXWhisperDownloadWorker" in content:
            print(f"   âœ… Pipeline åŒ…å« MLX ä¸‹è¼‰ Worker")
        else:
            print(f"   âŒ Pipeline ç¼ºå°‘ MLX ä¸‹è¼‰ Worker")
    except Exception as e:
        print(f"   âŒ æª¢æŸ¥å¤±æ•—: {e}")
    
    print("\n" + "=" * 60)
    print("æ¸¬è©¦å®Œæˆ")
    print("=" * 60)
    
    print("\nğŸ’¡ å¦‚ä½•æ¸¬è©¦é¦–æ¬¡ä¸‹è¼‰å°è©±æ¡†ï¼š")
    print("1. åˆªé™¤ MLX Whisper ç·©å­˜:")
    print("   rm -rf ~/.cache/huggingface/hub/models--mlx-community--whisper-large-v3-mlx")
    print("\n2. é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼")
    print("\n3. åŠ è¼‰è¦–é »ä¸¦é»æ“Šã€Œé–‹å§‹è½‰å¯«ã€")
    print("\n4. æ‡‰è©²æœƒçœ‹åˆ°ä¸‹è¼‰é€²åº¦å°è©±æ¡†")

if __name__ == "__main__":
    test_download_trigger()

