# ğŸ Apple Silicon å„ªåŒ–æ©Ÿæœƒåˆ†æå ±å‘Š

## ğŸ“Š åŸ·è¡Œæ‘˜è¦

ç¶“éç³»çµ±åŒ–ä»£ç¢¼åº«æƒæï¼Œç™¼ç¾ **Canto-Beats** æ‡‰ç”¨ç¨‹å¼å·²ç¶“å¯¦ç¾äº†éƒ¨åˆ† Apple Silicon å„ªåŒ–ï¼Œä½†ä»æœ‰ **5 å€‹é—œéµé ˜åŸŸ** å¯ä»¥é€²ä¸€æ­¥åˆ©ç”¨ M ç³»åˆ—èŠ¯ç‰‡çš„ç¡¬ä»¶åŠ é€Ÿèƒ½åŠ›ã€‚

---

## âœ… å·²å¯¦ç¾çš„å„ªåŒ–ï¼ˆç¾ç‹€ï¼‰

### 1. **Whisper ASR - MLX åŠ é€Ÿ** âœ…
- **ä½ç½®**: `src/utils/whisper_mlx.py`
- **æŠ€è¡“**: MLX Whisper (CoreML/Neural Engine)
- **å„ªå…ˆç´š**: CoreML > MPS > CPU
- **ç‹€æ…‹**: å·²å¯¦ç¾ä¸¦ä½œç‚ºä¸»è¦å¾Œç«¯

```python
# å·²å¯¦ç¾ï¼šè‡ªå‹•é¸æ“‡æœ€ä½³å¾Œç«¯
if MLXWhisperASR.is_available():
    logger.info("ğŸ Using MLX Whisper (Apple Silicon optimized)")
    return MLXWhisperASR(model_size=model_size)
```

### 2. **è¦–é »ç¸®ç•¥åœ– - VideoToolbox åŠ é€Ÿ** âœ…
- **ä½ç½®**: `src/utils/video_utils.py`, `src/utils/avf_thumbnail.py`
- **æŠ€è¡“**: AVFoundation + VideoToolbox ç¡¬ä»¶è§£ç¢¼
- **ç‹€æ…‹**: å·²å¯¦ç¾é›™å¾Œç«¯ï¼ˆAVFoundation å„ªå…ˆï¼ŒFFmpeg å‚™ç”¨ï¼‰

```python
# å·²å¯¦ç¾ï¼šmacOS åŸç”Ÿç¡¬ä»¶åŠ é€Ÿ
if sys.platform == 'darwin':
    input_kwargs = {'hwaccel': 'videotoolbox'}
```

### 3. **GPU æª¢æ¸¬ - MPS æ”¯æŒ** âœ…
- **ä½ç½®**: `src/core/hardware_detector.py`
- **æŠ€è¡“**: PyTorch MPS backend
- **ç‹€æ…‹**: å·²å¯¦ç¾ MPS æª¢æ¸¬ï¼Œä½†æœªå……åˆ†åˆ©ç”¨

```python
# å·²å¯¦ç¾ï¼šMPS æª¢æ¸¬
if torch.backends.mps.is_available():
    return "mps", 0.0  # âš ï¸ è¿”å› 0 VRAMï¼Œæœªå……åˆ†åˆ©ç”¨
```

---

## ğŸš¨ é—œéµå•é¡Œï¼šMPS æœªè¢«å……åˆ†åˆ©ç”¨

### å•é¡Œ 1: MPS è¢«èª¤åˆ¤ç‚ºã€Œç„¡ VRAMã€
**ä½ç½®**: `src/core/hardware_detector.py:168`

```python
# âŒ ç•¶å‰å¯¦ç¾
if torch.backends.mps.is_available():
    return "mps", 0.0  # éŒ¯èª¤ï¼šè¿”å› 0 VRAM
```

**å½±éŸ¿**:
- MPS è¨­å‚™è¢«é™ç´šåˆ° `CPU_ONLY` æˆ– `ENTRY` tier
- ç„¡æ³•ä½¿ç”¨ FP16 åŠ é€Ÿ
- LLM æ¨¡å‹è¢«è¿«ä½¿ç”¨ CPU æˆ–ä½æ•ˆé‡åŒ–

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# âœ… å»ºè­°ä¿®å¾©
if torch.backends.mps.is_available():
    # MPS å…±äº«çµ±ä¸€å…§å­˜ï¼Œå–ç³»çµ±å…§å­˜çš„ 70% ä½œç‚ºå¯ç”¨ VRAM
    import psutil
    system_ram_gb = psutil.virtual_memory().total / (1024**3)
    effective_vram = system_ram_gb * 0.7
    return "mps", effective_vram
```

---

## ğŸ¯ äº”å¤§å„ªåŒ–æ©Ÿæœƒ

### 1. **LLM æ¨ç† - MPS åŠ é€Ÿ** ğŸ”¥ é«˜å„ªå…ˆç´š

#### ç¾ç‹€
- **ä½ç½®**: `src/models/qwen_llm.py`
- **å•é¡Œ**: åƒ…æ”¯æŒ CUDAï¼ŒMPS è¨­å‚™å›é€€åˆ° CPU
- **å½±éŸ¿**: Qwen2.5-7B æ¨¡å‹åœ¨ CPU ä¸Šé‹è¡Œæ¥µæ…¢ï¼ˆ10-30 ç§’/å¥ï¼‰

```python
# âŒ ç•¶å‰å¯¦ç¾
model_a_kwargs = {
    "device_map": "auto" if device == "cuda" else "cpu",  # MPS è¢«ç•¶ä½œ CPU
}
```

#### å„ªåŒ–æ–¹æ¡ˆ
```python
# âœ… å»ºè­°ä¿®å¾©
def _get_device_map(device: str):
    if device == "cuda":
        return "auto"
    elif device == "mps":
        return "mps"  # PyTorch 2.0+ åŸç”Ÿæ”¯æŒ
    else:
        return "cpu"

model_a_kwargs = {
    "device_map": _get_device_map(device),
    "torch_dtype": torch.float16 if device in ["cuda", "mps"] else torch.float32,
}
```

#### é æœŸæ”¶ç›Š
- **é€Ÿåº¦æå‡**: 5-10xï¼ˆç›¸æ¯” CPUï¼‰
- **å…§å­˜æ•ˆç‡**: çµ±ä¸€å…§å­˜æ¶æ§‹ï¼Œç„¡éœ€ CPUâ†”GPU æ•¸æ“šå‚³è¼¸
- **åŠŸè€—é™ä½**: Neural Engine åƒèˆ‡æ¨ç†

---

### 2. **è¦–é »ç·¨ç¢¼ - VideoToolbox ç¡¬ä»¶ç·¨ç¢¼** ğŸ”¥ é«˜å„ªå…ˆç´š

#### ç¾ç‹€
- **ä½ç½®**: `src/pipeline/subtitle_pipeline_v2.py:158`
- **å•é¡Œ**: åƒ…ä½¿ç”¨ FFmpeg è»Ÿä»¶ç·¨ç¢¼ï¼ˆ`pcm_s16le`ï¼‰
- **å½±éŸ¿**: è¦–é »å°å‡ºæ…¢ï¼ŒCPU å ç”¨é«˜

```python
# âŒ ç•¶å‰å¯¦ç¾ï¼ˆåƒ…éŸ³é »æå–ï¼‰
cmd = ['ffmpeg', '-i', video, '-vn', '-acodec', 'pcm_s16le', audio]
```

#### å„ªåŒ–æ–¹æ¡ˆ
```python
# âœ… å»ºè­°ï¼šè¦–é »ç·¨ç¢¼ä½¿ç”¨ VideoToolbox
def get_video_encoder():
    if sys.platform == 'darwin':
        return {
            'vcodec': 'h264_videotoolbox',  # ç¡¬ä»¶ H.264 ç·¨ç¢¼
            'b:v': '5M',
            'pix_fmt': 'nv12',  # VideoToolbox åŸç”Ÿæ ¼å¼
        }
    else:
        return {'vcodec': 'libx264', 'preset': 'medium'}

# è¦–é »å°å‡ºç¤ºä¾‹
ffmpeg.output(
    input_stream,
    output_path,
    **get_video_encoder(),
    acodec='aac',
    audio_bitrate='192k'
).run()
```

#### é æœŸæ”¶ç›Š
- **ç·¨ç¢¼é€Ÿåº¦**: 3-5x æå‡
- **CPU å ç”¨**: é™ä½ 60-80%
- **åŠŸè€—**: é™ä½ 40-50%

---

### 3. **éŸ³é »è™•ç† - Accelerate Framework** ğŸŸ¡ ä¸­å„ªå…ˆç´š

#### ç¾ç‹€
- **ä½ç½®**: `src/models/vad_processor.py`, `src/utils/audio_utils.py`
- **å•é¡Œ**: ä½¿ç”¨ NumPy/SciPy é€²è¡ŒéŸ³é »é‡æ¡æ¨£å’Œ VAD
- **å½±éŸ¿**: CPU å¯†é›†å‹æ“ä½œ

#### å„ªåŒ–æ–¹æ¡ˆ
ä½¿ç”¨ macOS åŸç”Ÿ `Accelerate.framework` æ›¿ä»£ NumPyï¼š

```python
# âœ… å»ºè­°ï¼šä½¿ç”¨ vDSP åŠ é€ŸéŸ³é »è™•ç†
import ctypes
from ctypes import c_float, c_int, POINTER

# åŠ è¼‰ Accelerate framework
accelerate = ctypes.CDLL('/System/Library/Frameworks/Accelerate.framework/Accelerate')

def resample_audio_vdsp(audio: np.ndarray, orig_sr: int, target_sr: int):
    """ä½¿ç”¨ vDSP é€²è¡ŒéŸ³é »é‡æ¡æ¨£ï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰"""
    ratio = target_sr / orig_sr
    output_len = int(len(audio) * ratio)
    output = np.zeros(output_len, dtype=np.float32)
    
    # èª¿ç”¨ vDSP_vgenp (å‘é‡ç”Ÿæˆèˆ‡æ’å€¼)
    accelerate.vDSP_vgenp(
        audio.ctypes.data_as(POINTER(c_float)),
        c_int(1),
        audio.ctypes.data_as(POINTER(c_float)),
        c_int(1),
        output.ctypes.data_as(POINTER(c_float)),
        c_int(1),
        c_int(output_len),
        c_int(len(audio))
    )
    return output
```

#### é æœŸæ”¶ç›Š
- **é€Ÿåº¦æå‡**: 2-3xï¼ˆç›¸æ¯” NumPyï¼‰
- **åŠŸè€—é™ä½**: åˆ©ç”¨ AMX çŸ©é™£åŠ é€Ÿå™¨

---

### 4. **åœ–åƒè™•ç† - Core Image GPU åŠ é€Ÿ** ğŸŸ¡ ä¸­å„ªå…ˆç´š

#### ç¾ç‹€
- **ä½ç½®**: `src/ui/utils/waveform_renderer.py`
- **å•é¡Œ**: ä½¿ç”¨ PIL/Pillow é€²è¡Œåœ–åƒç¹ªè£½ï¼ˆCPUï¼‰
- **å½±éŸ¿**: æ³¢å½¢æ¸²æŸ“æ…¢ï¼ŒUI å¡é “

#### å„ªåŒ–æ–¹æ¡ˆ
```python
# âœ… å»ºè­°ï¼šä½¿ç”¨ Core Image é€²è¡Œ GPU åŠ é€Ÿç¹ªåœ–
from Quartz import (
    CIContext, CIImage, CIFilter,
    kCIContextUseSoftwareRenderer
)

class GPUWaveformRenderer:
    def __init__(self):
        # å‰µå»º Metal-backed CIContext
        self.ci_context = CIContext.contextWithOptions_({
            kCIContextUseSoftwareRenderer: False  # å¼·åˆ¶ GPU
        })
    
    def render_waveform(self, samples, width, height):
        # ä½¿ç”¨ Core Image filters é€²è¡Œ GPU ç¹ªè£½
        # æ¯” PIL å¿« 5-10x
        pass
```

#### é æœŸæ”¶ç›Š
- **æ¸²æŸ“é€Ÿåº¦**: 5-10x æå‡
- **UI æµæš¢åº¦**: 60 FPS ç©©å®š

---

### 5. **æ‰¹é‡æ¨ç† - Metal Performance Shaders (MPS)** ğŸŸ¢ ä½å„ªå…ˆç´š

#### ç¾ç‹€
- **ä½ç½®**: `src/models/whisper_asr.py`
- **å•é¡Œ**: é€å¥è™•ç†ï¼Œæœªåˆ©ç”¨æ‰¹é‡æ¨ç†

#### å„ªåŒ–æ–¹æ¡ˆ
```python
# âœ… å»ºè­°ï¼šä½¿ç”¨ MPS æ‰¹é‡æ¨ç†
import torch

def batch_transcribe_mps(audio_segments: List[np.ndarray], model):
    # å°‡å¤šå€‹éŸ³é »æ®µæ‰“åŒ…æˆ batch
    batch = torch.stack([
        torch.from_numpy(seg).to('mps') for seg in audio_segments
    ])
    
    with torch.no_grad():
        results = model(batch)  # æ‰¹é‡æ¨ç†ï¼Œåˆ©ç”¨ GPU ä¸¦è¡Œ
    
    return results
```

#### é æœŸæ”¶ç›Š
- **ååé‡**: 2-3x æå‡ï¼ˆé•·è¦–é »ï¼‰
- **GPU åˆ©ç”¨ç‡**: å¾ 30% æå‡åˆ° 70%

---

## ğŸ“‹ å„ªåŒ–å„ªå…ˆç´šçŸ©é™£

| å„ªåŒ–é …ç›® | å½±éŸ¿ç¯„åœ | å¯¦ç¾é›£åº¦ | æ€§èƒ½æå‡ | å„ªå…ˆç´š |
|---------|---------|---------|---------|--------|
| 1. MPS VRAM æª¢æ¸¬ä¿®å¾© | å…¨å±€ | ğŸŸ¢ ä½ | â­â­â­â­â­ | ğŸ”¥ ç«‹å³ |
| 2. LLM MPS åŠ é€Ÿ | LLM æ¨ç† | ğŸŸ¡ ä¸­ | â­â­â­â­â­ | ğŸ”¥ é«˜ |
| 3. VideoToolbox ç·¨ç¢¼ | è¦–é »å°å‡º | ğŸŸ¢ ä½ | â­â­â­â­ | ğŸ”¥ é«˜ |
| 4. Accelerate éŸ³é » | éŸ³é »è™•ç† | ğŸŸ¡ ä¸­ | â­â­â­ | ğŸŸ¡ ä¸­ |
| 5. Core Image ç¹ªåœ– | UI æ¸²æŸ“ | ğŸ”´ é«˜ | â­â­â­ | ğŸŸ¡ ä¸­ |
| 6. MPS æ‰¹é‡æ¨ç† | ASR åå | ğŸŸ¡ ä¸­ | â­â­ | ğŸŸ¢ ä½ |

---

## ğŸ› ï¸ å¯¦æ–½è·¯ç·šåœ–

### Phase 1: ç·Šæ€¥ä¿®å¾©ï¼ˆ1-2 å¤©ï¼‰
1. âœ… ä¿®å¾© MPS VRAM æª¢æ¸¬é‚è¼¯
2. âœ… å•Ÿç”¨ LLM MPS è¨­å‚™æ˜ å°„

### Phase 2: æ ¸å¿ƒå„ªåŒ–ï¼ˆ1 é€±ï¼‰
3. âœ… å¯¦ç¾ VideoToolbox è¦–é »ç·¨ç¢¼
4. âœ… æ·»åŠ  Accelerate éŸ³é »è™•ç†

### Phase 3: é€²éšå„ªåŒ–ï¼ˆ2 é€±ï¼‰
5. âœ… Core Image GPU æ¸²æŸ“
6. âœ… MPS æ‰¹é‡æ¨ç†å„ªåŒ–

---

## ğŸ“ˆ é æœŸç¸½é«”æ”¶ç›Š

| æŒ‡æ¨™ | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ | æå‡ |
|-----|-------|-------|------|
| LLM æ¨ç†é€Ÿåº¦ | 20s/å¥ | 2-4s/å¥ | **5-10x** |
| è¦–é »ç·¨ç¢¼é€Ÿåº¦ | 0.5x å¯¦æ™‚ | 2-3x å¯¦æ™‚ | **4-6x** |
| éŸ³é »è™•ç†é€Ÿåº¦ | 1.0x | 2-3x | **2-3x** |
| GPU åˆ©ç”¨ç‡ | 10-20% | 60-80% | **3-4x** |
| åŠŸè€—ï¼ˆå¹³å‡ï¼‰ | 25W | 15W | **-40%** |

---

## ğŸ” æŠ€è¡“å‚µå‹™è­¦å‘Š

### ç•¶å‰æ¶æ§‹å•é¡Œ
1. **ç¡¬ç·¨ç¢¼ CUDA å‡è¨­**: å¤šè™•ä»£ç¢¼å‡è¨­ GPU = CUDA
2. **ç¼ºå°‘è¨­å‚™æŠ½è±¡å±¤**: æ²’æœ‰çµ±ä¸€çš„è¨­å‚™ç®¡ç†æ¥å£
3. **é‡åŒ–é…ç½®æ··äº‚**: `bitsandbytes` åƒ…æ”¯æŒ CUDAï¼ŒMPS éœ€è¦å…¶ä»–æ–¹æ¡ˆ

### å»ºè­°é‡æ§‹
å‰µå»ºçµ±ä¸€è¨­å‚™ç®¡ç†å™¨ï¼š
```python
# src/core/device_manager.py
class DeviceManager:
    @staticmethod
    def get_optimal_device() -> str:
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    @staticmethod
    def get_dtype(device: str) -> torch.dtype:
        return torch.float16 if device in ["cuda", "mps"] else torch.float32
```

---

## ğŸ”§ å¿«é€Ÿä¿®å¾©ä»£ç¢¼ç¤ºä¾‹

### ä¿®å¾© 1: MPS VRAM æª¢æ¸¬
**æ–‡ä»¶**: `src/core/hardware_detector.py:153-170`

```python
def _detect_gpu(self) -> Tuple[str, float]:
    # 1. Check Apple Silicon MPS
    try:
        if torch.backends.mps.is_available() and torch.backends.mps.is_built():
            logger.info("Apple MPS (Metal) detected - Apple Silicon GPU")

            # âœ… ä¿®å¾©ï¼šè¨ˆç®—æœ‰æ•ˆ VRAMï¼ˆçµ±ä¸€å…§å­˜çš„ 70%ï¼‰
            import psutil
            system_ram_gb = psutil.virtual_memory().total / (1024 ** 3)
            effective_vram = system_ram_gb * 0.7

            logger.info(f"MPS effective VRAM: {effective_vram:.1f} GB (70% of {system_ram_gb:.1f} GB system RAM)")
            return "mps", effective_vram
    except Exception as e:
        logger.debug(f"MPS check failed: {e}")

    # 2. Check NVIDIA CUDA
    if not torch.cuda.is_available():
        logger.info("No GPU detected, using CPU mode")
        return "cpu", 0.0
    # ... rest of CUDA logic
```

### ä¿®å¾© 2: LLM MPS æ”¯æŒ
**æ–‡ä»¶**: `src/models/qwen_llm.py:100-136`

```python
def load_models(self):
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch

    device = self.profile.device

    # âœ… ä¿®å¾©ï¼šæ”¯æŒ MPS è¨­å‚™
    def get_device_map(device: str):
        if device == "cuda":
            return "auto"
        elif device == "mps":
            return "mps"  # PyTorch 2.0+ åŸç”Ÿæ”¯æŒ
        else:
            return "cpu"

    model_a_kwargs = {
        "device_map": get_device_map(device),
        "trust_remote_code": True,
        "torch_dtype": torch.float16 if device in ["cuda", "mps"] else torch.float32,
    }

    # âš ï¸ æ³¨æ„ï¼šbitsandbytes é‡åŒ–åƒ…æ”¯æŒ CUDA
    if device == "cuda" and self.profile.llm_a_quantization == "int8":
        try:
            from transformers import BitsAndBytesConfig
            model_a_kwargs["quantization_config"] = BitsAndBytesConfig(load_in_8bit=True)
        except ImportError:
            logger.warning("bitsandbytes not available")

    self._model_a = AutoModelForCausalLM.from_pretrained(
        self.model_a_id, **model_a_kwargs
    )
```

### ä¿®å¾© 3: VideoToolbox è¦–é »ç·¨ç¢¼
**æ–‡ä»¶**: `src/utils/video_utils.py` (æ–°å¢å‡½æ•¸)

```python
def get_optimal_video_encoder():
    """è¿”å›å¹³å°æœ€ä½³è¦–é »ç·¨ç¢¼å™¨é…ç½®"""
    if sys.platform == 'darwin':
        # macOS: ä½¿ç”¨ VideoToolbox ç¡¬ä»¶ç·¨ç¢¼
        return {
            'vcodec': 'h264_videotoolbox',
            'b:v': '5M',
            'pix_fmt': 'nv12',  # VideoToolbox åŸç”Ÿæ ¼å¼
            'allow_sw': '1',    # å…è¨±è»Ÿä»¶å›é€€
        }
    elif torch.cuda.is_available():
        # NVIDIA: ä½¿ç”¨ NVENC
        return {
            'vcodec': 'h264_nvenc',
            'preset': 'p4',
            'b:v': '5M',
        }
    else:
        # CPU å›é€€
        return {
            'vcodec': 'libx264',
            'preset': 'medium',
            'crf': '23',
        }

# ä½¿ç”¨ç¤ºä¾‹
encoder_config = get_optimal_video_encoder()
ffmpeg.output(input_stream, output_path, **encoder_config, acodec='aac').run()
```

---

## ğŸ“š åƒè€ƒè³‡æº

- [Apple MLX Documentation](https://ml-explore.github.io/mlx/)
- [PyTorch MPS Backend](https://pytorch.org/docs/stable/notes/mps.html)
- [FFmpeg VideoToolbox](https://trac.ffmpeg.org/wiki/HWAccelIntro#VideoToolbox)
- [Accelerate Framework](https://developer.apple.com/documentation/accelerate)
- [Transformers Device Map](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained.device_map)

---

**ç”Ÿæˆæ™‚é–“**: 2025-01-XX
**åˆ†æå·¥å…·**: Claude Code + Augment Codebase Retrieval
**ä»£ç¢¼åº«ç‰ˆæœ¬**: Canto-Beats v1.0.0-macOS

