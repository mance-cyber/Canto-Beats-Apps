# ğŸš€ Apple Silicon å„ªåŒ–å¯¦æ–½æ¸…å–®

## âœ… Phase 1: ç·Šæ€¥ä¿®å¾©ï¼ˆé è¨ˆ 1-2 å¤©ï¼‰

### ä»»å‹™ 1.1: ä¿®å¾© MPS VRAM æª¢æ¸¬
- [ ] **æ–‡ä»¶**: `src/core/hardware_detector.py`
- [ ] **è¡Œæ•¸**: 153-170
- [ ] **è®Šæ›´**: 
  - æ·»åŠ  `psutil` ä¾è³´åˆ° `requirements-macos-silicon.txt`
  - è¨ˆç®—çµ±ä¸€å…§å­˜çš„ 70% ä½œç‚ºæœ‰æ•ˆ VRAM
  - æ›´æ–°æ—¥èªŒè¼¸å‡ºé¡¯ç¤ºå¯¦éš›å¯ç”¨å…§å­˜
- [ ] **æ¸¬è©¦**: 
  ```bash
  python -c "from src.core.hardware_detector import HardwareDetector; print(HardwareDetector().detect())"
  ```
- [ ] **é æœŸçµæœ**: M1/M2/M3 Mac æ‡‰é¡¯ç¤º `MAINSTREAM` æˆ– `ULTIMATE` tier

---

### ä»»å‹™ 1.2: å•Ÿç”¨ LLM MPS è¨­å‚™æ˜ å°„
- [ ] **æ–‡ä»¶**: `src/models/qwen_llm.py`
- [ ] **è¡Œæ•¸**: 100-136
- [ ] **è®Šæ›´**:
  - å‰µå»º `get_device_map()` è¼”åŠ©å‡½æ•¸
  - æ”¯æŒ `device_map="mps"` åƒæ•¸
  - ç‚º MPS è¨­å‚™å•Ÿç”¨ FP16 ç²¾åº¦
  - ç¦ç”¨ MPS ä¸Šçš„ `bitsandbytes` é‡åŒ–ï¼ˆåƒ… CUDA æ”¯æŒï¼‰
- [ ] **æ¸¬è©¦**:
  ```bash
  python test_qwen_mps.py  # éœ€å‰µå»ºæ¸¬è©¦è…³æœ¬
  ```
- [ ] **é æœŸçµæœ**: Qwen2.5-7B åœ¨ MPS ä¸ŠåŠ è¼‰ä¸¦æ¨ç†æˆåŠŸ

---

## ğŸ”¥ Phase 2: æ ¸å¿ƒå„ªåŒ–ï¼ˆé è¨ˆ 1 é€±ï¼‰

### ä»»å‹™ 2.1: VideoToolbox è¦–é »ç·¨ç¢¼
- [ ] **æ–‡ä»¶**: `src/utils/video_utils.py`
- [ ] **æ–°å¢å‡½æ•¸**: `get_optimal_video_encoder()`
- [ ] **è®Šæ›´**:
  - æª¢æ¸¬å¹³å°ä¸¦è¿”å›æœ€ä½³ç·¨ç¢¼å™¨é…ç½®
  - macOS: `h264_videotoolbox` / `hevc_videotoolbox`
  - CUDA: `h264_nvenc`
  - CPU: `libx264` å›é€€
- [ ] **é›†æˆä½ç½®**:
  - `src/pipeline/subtitle_pipeline_v2.py` (è¦–é »å°å‡º)
  - `src/ui/timeline_editor.py` (æ™‚é–“è»¸æ¸²æŸ“)
- [ ] **æ¸¬è©¦**:
  ```bash
  ffmpeg -f lavfi -i testsrc=duration=10:size=1920x1080:rate=30 \
         -c:v h264_videotoolbox -b:v 5M test_videotoolbox.mp4
  ```

---

### ä»»å‹™ 2.2: Accelerate Framework éŸ³é »è™•ç†
- [ ] **æ–‡ä»¶**: `src/utils/audio_utils.py`
- [ ] **æ–°å¢é¡**: `AccelerateAudioProcessor`
- [ ] **è®Šæ›´**:
  - ä½¿ç”¨ `vDSP` é€²è¡ŒéŸ³é »é‡æ¡æ¨£
  - ä½¿ç”¨ `vDSP_vgenp` é€²è¡Œå‘é‡æ’å€¼
  - å›é€€åˆ° NumPyï¼ˆé macOS å¹³å°ï¼‰
- [ ] **é›†æˆä½ç½®**:
  - `src/models/vad_processor.py` (VAD é è™•ç†)
  - `src/pipeline/subtitle_pipeline_v2.py` (éŸ³é »æå–)
- [ ] **æ¸¬è©¦**:
  ```python
  # æ€§èƒ½å°æ¯”æ¸¬è©¦
  import time
  audio = np.random.randn(48000 * 60)  # 1 åˆ†é˜éŸ³é »
  
  # NumPy ç‰ˆæœ¬
  start = time.time()
  resampled_numpy = resample_numpy(audio, 48000, 16000)
  print(f"NumPy: {time.time() - start:.3f}s")
  
  # Accelerate ç‰ˆæœ¬
  start = time.time()
  resampled_vdsp = resample_vdsp(audio, 48000, 16000)
  print(f"vDSP: {time.time() - start:.3f}s")
  ```

---

## ğŸ¨ Phase 3: é€²éšå„ªåŒ–ï¼ˆé è¨ˆ 2 é€±ï¼‰

### ä»»å‹™ 3.1: Core Image GPU æ¸²æŸ“
- [ ] **æ–‡ä»¶**: `src/ui/utils/waveform_renderer.py`
- [ ] **æ–°å¢é¡**: `CoreImageWaveformRenderer`
- [ ] **è®Šæ›´**:
  - ä½¿ç”¨ `CIContext` å‰µå»º Metal-backed æ¸²æŸ“ä¸Šä¸‹æ–‡
  - ä½¿ç”¨ `CIFilter` é€²è¡Œ GPU åŠ é€Ÿç¹ªåœ–
  - å›é€€åˆ° PILï¼ˆé macOS å¹³å°ï¼‰
- [ ] **ä¾è³´**: 
  ```bash
  pip install pyobjc-framework-Quartz pyobjc-framework-CoreImage
  ```
- [ ] **æ¸¬è©¦**: åœ¨æ™‚é–“è»¸ç·¨è¼¯å™¨ä¸­åŠ è¼‰é•·è¦–é »ï¼Œè§€å¯Ÿæ³¢å½¢æ¸²æŸ“é€Ÿåº¦

---

### ä»»å‹™ 3.2: MPS æ‰¹é‡æ¨ç†å„ªåŒ–
- [ ] **æ–‡ä»¶**: `src/models/whisper_asr.py`
- [ ] **æ–°å¢å‡½æ•¸**: `batch_transcribe_mps()`
- [ ] **è®Šæ›´**:
  - å°‡å¤šå€‹éŸ³é »æ®µæ‰“åŒ…æˆ batch tensor
  - ä½¿ç”¨ `torch.stack()` ä¸¦ç§»å‹•åˆ° MPS è¨­å‚™
  - æ‰¹é‡èª¿ç”¨ Whisper æ¨¡å‹
- [ ] **æ¸¬è©¦**: å°æ¯”å–®å¥ vs æ‰¹é‡æ¨ç†çš„ååé‡

---

## ğŸ§ª æ¸¬è©¦è¨ˆåŠƒ

### å–®å…ƒæ¸¬è©¦
```bash
# å‰µå»ºæ¸¬è©¦æ–‡ä»¶
touch tests/test_mps_optimization.py
touch tests/test_videotoolbox.py
touch tests/test_accelerate_audio.py
```

### æ€§èƒ½åŸºæº–æ¸¬è©¦
```python
# tests/benchmark_apple_silicon.py
import time
import torch
from src.core.hardware_detector import HardwareDetector
from src.models.qwen_llm import QwenLLM

def benchmark_llm_inference():
    detector = HardwareDetector()
    profile = detector.detect()
    
    llm = QwenLLM(config, profile)
    llm.load_models()
    
    test_sentences = ["å‘¢å€‹ä¿‚æ¸¬è©¦å¥å­"] * 10
    
    start = time.time()
    for sentence in test_sentences:
        llm.process_sentence(sentence)
    elapsed = time.time() - start
    
    print(f"Device: {profile.device}")
    print(f"Total time: {elapsed:.2f}s")
    print(f"Avg per sentence: {elapsed/len(test_sentences):.2f}s")
```

---

## ğŸ“Š é©—æ”¶æ¨™æº–

| æŒ‡æ¨™ | å„ªåŒ–å‰ | ç›®æ¨™ | é©—æ”¶æ–¹æ³• |
|-----|-------|------|---------|
| LLM æ¨ç†é€Ÿåº¦ (M2 Max) | 20s/å¥ | <4s/å¥ | `benchmark_llm_inference()` |
| è¦–é »ç·¨ç¢¼é€Ÿåº¦ (1080p) | 0.5x å¯¦æ™‚ | >2x å¯¦æ™‚ | FFmpeg ç·¨ç¢¼ 10 åˆ†é˜è¦–é » |
| éŸ³é »é‡æ¡æ¨£é€Ÿåº¦ | 1.0x | >2x | `benchmark_audio_resample()` |
| GPU åˆ©ç”¨ç‡ | <20% | >60% | Activity Monitor > GPU History |
| åŠŸè€—ï¼ˆå¹³å‡ï¼‰ | 25W | <18W | `sudo powermetrics --samplers cpu_power` |

---

## ğŸ› å·²çŸ¥å•é¡Œèˆ‡é™åˆ¶

### MPS é™åˆ¶
1. **ä¸æ”¯æŒ INT8 é‡åŒ–**: `bitsandbytes` åƒ…æ”¯æŒ CUDA
   - **è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨ FP16 æˆ–ç­‰å¾… Apple å®˜æ–¹æ”¯æŒ
2. **éƒ¨åˆ†ç®—å­æœªå¯¦ç¾**: æŸäº› PyTorch ç®—å­åœ¨ MPS ä¸Šæœƒå›é€€åˆ° CPU
   - **è§£æ±ºæ–¹æ¡ˆ**: ä½¿ç”¨ `torch.mps.is_available()` æª¢æ¸¬ä¸¦æä¾›å›é€€

### VideoToolbox é™åˆ¶
1. **åƒ…æ”¯æŒ H.264/HEVC**: ä¸æ”¯æŒ VP9/AV1
2. **è³ªé‡æ§åˆ¶æœ‰é™**: æ¯”ç‰¹ç‡æ§åˆ¶ä¸å¦‚ x264 ç²¾ç´°

---

## ğŸ“ æ–‡æª”æ›´æ–°

- [ ] æ›´æ–° `MACOS_SILICON_BUILD_GUIDE.md`
- [ ] æ›´æ–° `MACOS_TECHNICAL_NOTES.md`
- [ ] å‰µå»º `APPLE_SILICON_PERFORMANCE_TUNING.md`
- [ ] æ›´æ–° `README.md` æ·»åŠ æ€§èƒ½å°æ¯”è¡¨

---

**å‰µå»ºæ™‚é–“**: 2025-01-XX  
**è² è²¬äºº**: Development Team  
**é è¨ˆå®Œæˆ**: Phase 1-3 å…± 3-4 é€±

