#!/usr/bin/env python3
"""
Apple Silicon å„ªåŒ–æ•ˆæœæ¸¬è©¦è…³æœ¬

æ¸¬è©¦ MPS åŠ é€Ÿã€VideoToolbox ç·¨ç¢¼ç­‰å„ªåŒ–çš„å¯¦éš›æ€§èƒ½æå‡ã€‚

ä½¿ç”¨æ–¹æ³•:
    python test_apple_silicon_performance.py
"""

import sys
import time
import platform
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

# ==================== æ¸¬è©¦ 1: ç¡¬ä»¶æª¢æ¸¬ ====================
def test_hardware_detection():
    print("\n" + "="*60)
    print("æ¸¬è©¦ 1: ç¡¬ä»¶æª¢æ¸¬èˆ‡ VRAM è¨ˆç®—")
    print("="*60)
    
    try:
        from src.core.hardware_detector import HardwareDetector
        
        detector = HardwareDetector()
        profile = detector.detect()
        
        print(f"âœ… æª¢æ¸¬æˆåŠŸ")
        print(f"  è¨­å‚™: {profile.device}")
        print(f"  VRAM: {profile.vram_gb:.1f} GB")
        print(f"  æ€§èƒ½ç­‰ç´š: {profile.tier.value}")
        print(f"  æè¿°: {profile.description}")
        
        # é©—è­‰ MPS è¨­å‚™æ˜¯å¦æ­£ç¢ºè­˜åˆ¥
        if profile.device == "mps" and profile.vram_gb > 0:
            print(f"  âœ… MPS VRAM æª¢æ¸¬æ­£å¸¸")
        elif profile.device == "mps" and profile.vram_gb == 0:
            print(f"  âŒ MPS VRAM ä»ç‚º 0ï¼Œä¿®å¾©æœªç”Ÿæ•ˆ")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

# ==================== æ¸¬è©¦ 2: PyTorch MPS ====================
def test_pytorch_mps():
    print("\n" + "="*60)
    print("æ¸¬è©¦ 2: PyTorch MPS å¾Œç«¯")
    print("="*60)
    
    try:
        import torch
        
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"MPS å¯ç”¨: {torch.backends.mps.is_available()}")
        print(f"MPS å·²æ§‹å»º: {torch.backends.mps.is_built()}")
        
        if not torch.backends.mps.is_available():
            print("âš ï¸  MPS ä¸å¯ç”¨ï¼ˆå¯èƒ½ä¸æ˜¯ Apple Silicon Macï¼‰")
            return True
        
        # æ¸¬è©¦ MPS å¼µé‡é‹ç®—
        print("\næ¸¬è©¦ MPS å¼µé‡é‹ç®—...")
        x = torch.randn(1000, 1000, device='mps')
        y = torch.randn(1000, 1000, device='mps')
        
        start = time.time()
        z = torch.matmul(x, y)
        torch.mps.synchronize()  # ç­‰å¾… GPU å®Œæˆ
        elapsed = time.time() - start
        
        print(f"  âœ… çŸ©é™£ä¹˜æ³• (1000x1000): {elapsed*1000:.2f} ms")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

# ==================== æ¸¬è©¦ 3: LLM MPS åŠ è¼‰ ====================
def test_llm_mps_loading():
    print("\n" + "="*60)
    print("æ¸¬è©¦ 3: LLM æ¨¡å‹ MPS åŠ è¼‰")
    print("="*60)
    
    try:
        import torch
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        if not torch.backends.mps.is_available():
            print("âš ï¸  è·³éï¼ˆMPS ä¸å¯ç”¨ï¼‰")
            return True
        
        # ä½¿ç”¨å°æ¨¡å‹æ¸¬è©¦
        model_id = "Qwen/Qwen2.5-0.5B-Instruct"  # 500M åƒæ•¸ï¼Œå¿«é€Ÿæ¸¬è©¦
        
        print(f"åŠ è¼‰æ¸¬è©¦æ¨¡å‹: {model_id}")
        print("  (é¦–æ¬¡é‹è¡Œæœƒä¸‹è¼‰æ¨¡å‹ï¼Œè«‹è€å¿ƒç­‰å¾…...)")
        
        start = time.time()
        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            device_map="mps",
            torch_dtype=torch.float16,
            trust_remote_code=True
        )
        load_time = time.time() - start
        
        print(f"  âœ… æ¨¡å‹åŠ è¼‰æˆåŠŸ ({load_time:.1f}s)")
        print(f"  è¨­å‚™: {model.device}")
        
        # æ¸¬è©¦æ¨ç†
        print("\næ¸¬è©¦æ¨ç†...")
        inputs = tokenizer("ä½ å¥½", return_tensors="pt").to('mps')
        
        start = time.time()
        with torch.no_grad():
            outputs = model.generate(**inputs, max_new_tokens=10)
        torch.mps.synchronize()
        inference_time = time.time() - start
        
        result = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"  âœ… æ¨ç†æˆåŠŸ ({inference_time:.2f}s)")
        print(f"  è¼¸å‡º: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

# ==================== æ¸¬è©¦ 4: FFmpeg VideoToolbox ====================
def test_videotoolbox():
    print("\n" + "="*60)
    print("æ¸¬è©¦ 4: FFmpeg VideoToolbox æ”¯æŒ")
    print("="*60)
    
    try:
        import subprocess
        
        # æª¢æŸ¥ FFmpeg æ˜¯å¦å®‰è£
        result = subprocess.run(
            ['ffmpeg', '-version'],
            capture_output=True,
            text=True,
            timeout=5
        )
        
        if result.returncode != 0:
            print("âŒ FFmpeg æœªå®‰è£")
            return False
        
        print(f"âœ… FFmpeg å·²å®‰è£")
        
        # æª¢æŸ¥ç¡¬ä»¶åŠ é€Ÿæ”¯æŒ
        result = subprocess.run(
            ['ffmpeg', '-hwaccels'],
            capture_output=True,
            text=True,
            timeout=5
        )
        
        hwaccels = result.stdout.lower()
        print(f"\næ”¯æŒçš„ç¡¬ä»¶åŠ é€Ÿ:")
        for line in result.stdout.strip().split('\n')[1:]:  # è·³éæ¨™é¡Œè¡Œ
            print(f"  - {line}")
        
        if 'videotoolbox' in hwaccels:
            print(f"\n  âœ… VideoToolbox å¯ç”¨")
        else:
            print(f"\n  âš ï¸  VideoToolbox ä¸å¯ç”¨")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

# ==================== ä¸»ç¨‹åº ====================
def main():
    print("\n" + "="*70)
    print(" "*15 + "Apple Silicon å„ªåŒ–æ•ˆæœæ¸¬è©¦")
    print("="*70)
    
    print(f"\nç³»çµ±ä¿¡æ¯:")
    print(f"  å¹³å°: {platform.system()} {platform.release()}")
    print(f"  è™•ç†å™¨: {platform.processor()}")
    print(f"  æ¶æ§‹: {platform.machine()}")
    
    # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
    tests = [
        ("ç¡¬ä»¶æª¢æ¸¬", test_hardware_detection),
        ("PyTorch MPS", test_pytorch_mps),
        ("LLM MPS åŠ è¼‰", test_llm_mps_loading),
        ("VideoToolbox", test_videotoolbox),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            success = test_func()
            results.append((name, success))
        except KeyboardInterrupt:
            print("\n\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
            sys.exit(1)
        except Exception as e:
            print(f"\nâŒ æ¸¬è©¦ç•°å¸¸: {e}")
            results.append((name, False))
    
    # ç¸½çµ
    print("\n" + "="*70)
    print("æ¸¬è©¦ç¸½çµ")
    print("="*70)
    
    for name, success in results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"  {status}  {name}")
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Apple Silicon å„ªåŒ–å·²ç”Ÿæ•ˆã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤ä¿¡æ¯ã€‚")
    
    print("="*70 + "\n")

if __name__ == "__main__":
    main()

