"""
Vocabulary Learner - ç”¨æˆ¶è©å½™å­¸ç¿’æ¨¡çµ„

å¾ç”¨æˆ¶çš„ä¿®æ­£ä¸­å­¸ç¿’ï¼Œæé«˜å€‹äººåŒ–è¾¨è­˜æº–ç¢ºåº¦ï¼š
1. è¨˜éŒ„ç”¨æˆ¶ä¿®æ­£çš„è©å½™
2. å»ºç«‹å€‹äººåŒ–è©å½™åº«
3. ç”Ÿæˆ Whisper æç¤ºè©
4. è‡ªå‹•æ ¡æ­£å¸¸è¦‹éŒ¯èª¤
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import Counter
from datetime import datetime

from utils.logger import setup_logger

logger = setup_logger()


@dataclass
class VocabularyEntry:
    """è©å½™æ¢ç›®"""
    correct_word: str           # æ­£ç¢ºå¯«æ³•
    wrong_variants: List[str]   # éŒ¯èª¤è®Šé«”åˆ—è¡¨
    frequency: int              # ä½¿ç”¨é »ç‡
    category: str               # é¡åˆ¥ï¼ˆäººåã€åœ°åã€å°ˆæœ‰åè©ç­‰ï¼‰
    last_used: str              # æœ€å¾Œä½¿ç”¨æ™‚é–“
    user_added: bool = True     # æ˜¯å¦ç”±ç”¨æˆ¶æ·»åŠ 


class VocabularyLearner:
    """
    ç”¨æˆ¶è©å½™å­¸ç¿’å™¨

    åŠŸèƒ½ï¼š
    1. å¾ç”¨æˆ¶ä¿®æ­£ä¸­è‡ªå‹•å­¸ç¿’
    2. å»ºç«‹å€‹äººåŒ–è©å½™åº«
    3. ç”Ÿæˆ Whisper prompt æé«˜è¾¨è­˜ç‡
    4. è‡ªå‹•æ ¡æ­£å·²çŸ¥éŒ¯èª¤
    """

    def __init__(self, data_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–è©å½™å­¸ç¿’å™¨

        Args:
            data_dir: æ•¸æ“šå­˜å„²ç›®éŒ„
        """
        if data_dir is None:
            data_dir = Path.home() / ".canto_beats"
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

        self.vocab_file = self.data_dir / "user_vocabulary.json"
        self.corrections_file = self.data_dir / "user_corrections.json"

        # åŠ è¼‰ç¾æœ‰æ•¸æ“š
        self.vocabulary: Dict[str, VocabularyEntry] = {}
        self.corrections_history: List[Dict] = []

        self._load_data()

    # ==================== æ•¸æ“šæŒä¹…åŒ– ====================

    def _load_data(self):
        """åŠ è¼‰ä¿å­˜çš„è©å½™æ•¸æ“š"""
        # åŠ è¼‰è©å½™åº«
        if self.vocab_file.exists():
            try:
                with open(self.vocab_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for word, entry_data in data.items():
                        self.vocabulary[word] = VocabularyEntry(**entry_data)
                logger.info(f"âœ… åŠ è¼‰ {len(self.vocabulary)} å€‹ç”¨æˆ¶è©å½™")
            except Exception as e:
                logger.warning(f"åŠ è¼‰è©å½™åº«å¤±æ•—: {e}")

        # åŠ è¼‰ä¿®æ­£æ­·å²
        if self.corrections_file.exists():
            try:
                with open(self.corrections_file, 'r', encoding='utf-8') as f:
                    self.corrections_history = json.load(f)
                logger.info(f"âœ… åŠ è¼‰ {len(self.corrections_history)} æ¢ä¿®æ­£æ­·å²")
            except Exception as e:
                logger.warning(f"åŠ è¼‰ä¿®æ­£æ­·å²å¤±æ•—: {e}")

    def _save_data(self):
        """ä¿å­˜è©å½™æ•¸æ“š"""
        # ä¿å­˜è©å½™åº«
        try:
            vocab_data = {
                word: asdict(entry)
                for word, entry in self.vocabulary.items()
            }
            with open(self.vocab_file, 'w', encoding='utf-8') as f:
                json.dump(vocab_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è©å½™åº«å¤±æ•—: {e}")

        # ä¿å­˜ä¿®æ­£æ­·å²
        try:
            with open(self.corrections_file, 'w', encoding='utf-8') as f:
                json.dump(self.corrections_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ä¿®æ­£æ­·å²å¤±æ•—: {e}")

    # ==================== å­¸ç¿’åŠŸèƒ½ ====================

    def learn_from_correction(
        self,
        original: str,
        corrected: str,
        context: str = "",
        category: str = "general"
    ):
        """
        å¾ç”¨æˆ¶ä¿®æ­£ä¸­å­¸ç¿’

        Args:
            original: åŸå§‹ï¼ˆéŒ¯èª¤ï¼‰æ–‡å­—
            corrected: ä¿®æ­£å¾Œæ–‡å­—
            context: ä¸Šä¸‹æ–‡ï¼ˆå¯é¸ï¼‰
            category: é¡åˆ¥ï¼ˆäººåã€åœ°åç­‰ï¼‰
        """
        if original == corrected:
            return

        # æå–å·®ç•°è©å½™
        diff_pairs = self._extract_diff_pairs(original, corrected)

        for wrong, correct in diff_pairs:
            if not correct or not wrong:
                continue

            # è¨˜éŒ„åˆ°ä¿®æ­£æ­·å²
            self.corrections_history.append({
                "timestamp": datetime.now().isoformat(),
                "wrong": wrong,
                "correct": correct,
                "context": context,
                "category": category
            })

            # æ›´æ–°è©å½™åº«
            if correct in self.vocabulary:
                # å·²å­˜åœ¨ï¼Œæ›´æ–°
                entry = self.vocabulary[correct]
                if wrong not in entry.wrong_variants:
                    entry.wrong_variants.append(wrong)
                entry.frequency += 1
                entry.last_used = datetime.now().isoformat()
            else:
                # æ–°è©å½™
                self.vocabulary[correct] = VocabularyEntry(
                    correct_word=correct,
                    wrong_variants=[wrong],
                    frequency=1,
                    category=category,
                    last_used=datetime.now().isoformat(),
                    user_added=True
                )

            logger.info(f"ğŸ“š å­¸ç¿’æ–°ä¿®æ­£: '{wrong}' â†’ '{correct}'")

        # ä¿å­˜
        self._save_data()

    def _extract_diff_pairs(
        self,
        original: str,
        corrected: str
    ) -> List[Tuple[str, str]]:
        """
        æå–åŸå§‹å’Œä¿®æ­£æ–‡å­—ä¹‹é–“çš„å·®ç•°è©å½™å°

        ä½¿ç”¨ç°¡å–®çš„å­—ç¬¦æ¯”å°ç®—æ³•
        """
        pairs = []

        # ç°¡å–®ç­–ç•¥ï¼šæŒ‰ç©ºæ ¼/æ¨™é»åˆ†è©ï¼Œæ¯”è¼ƒå·®ç•°
        import re

        # åˆ†è©
        orig_words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+', original)
        corr_words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+', corrected)

        # ä½¿ç”¨ SequenceMatcher æ‰¾å·®ç•°
        from difflib import SequenceMatcher
        matcher = SequenceMatcher(None, orig_words, corr_words)

        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'replace':
                # æ›¿æ›çš„è©
                orig_segment = ''.join(orig_words[i1:i2])
                corr_segment = ''.join(corr_words[j1:j2])
                if orig_segment and corr_segment:
                    pairs.append((orig_segment, corr_segment))

        return pairs

    # ==================== è‡ªå‹•æ ¡æ­£ ====================

    def auto_correct(self, text: str) -> str:
        """
        ä½¿ç”¨å­¸ç¿’çš„è©å½™è‡ªå‹•æ ¡æ­£æ–‡æœ¬

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            æ ¡æ­£å¾Œæ–‡æœ¬
        """
        if not self.vocabulary:
            return text

        result = text
        corrections_made = []

        # æŒ‰é »ç‡æ’åºï¼ˆé«˜é »è©å„ªå…ˆï¼‰
        sorted_vocab = sorted(
            self.vocabulary.items(),
            key=lambda x: x[1].frequency,
            reverse=True
        )

        for correct_word, entry in sorted_vocab:
            for wrong in entry.wrong_variants:
                if wrong in result:
                    result = result.replace(wrong, correct_word)
                    corrections_made.append((wrong, correct_word))

        if corrections_made:
            logger.info(f"ğŸ“ è‡ªå‹•æ ¡æ­£ {len(corrections_made)} è™•")
            for wrong, correct in corrections_made[:5]:
                logger.debug(f"  '{wrong}' â†’ '{correct}'")

        return result

    # ==================== Whisper Prompt ç”Ÿæˆ ====================

    def generate_whisper_prompt(
        self,
        max_words: int = 50,
        category_filter: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆ Whisper æç¤ºè©

        å°‡é«˜é »è©å½™åŠ å…¥æç¤ºï¼Œå¹«åŠ© Whisper æ›´æº–ç¢ºè¾¨è­˜

        Args:
            max_words: æœ€å¤§è©å½™æ•¸
            category_filter: åªåŒ…å«ç‰¹å®šé¡åˆ¥

        Returns:
            Whisper prompt å­—ä¸²
        """
        if not self.vocabulary:
            return ""

        # ç¯©é¸å’Œæ’åº
        filtered_vocab = [
            entry for entry in self.vocabulary.values()
            if category_filter is None or entry.category == category_filter
        ]

        # æŒ‰é »ç‡æ’åº
        sorted_vocab = sorted(
            filtered_vocab,
            key=lambda x: x.frequency,
            reverse=True
        )[:max_words]

        # ç”Ÿæˆæç¤ºè©
        words = [entry.correct_word for entry in sorted_vocab]
        prompt = "ä»¥ä¸‹ä¿‚å¸¸ç”¨è©å½™ï¼š" + "ã€".join(words)

        logger.info(f"ğŸ“‹ ç”Ÿæˆ Whisper promptï¼ˆ{len(words)} å€‹è©å½™ï¼‰")
        return prompt

    # ==================== è©å½™ç®¡ç† ====================

    def add_vocabulary(
        self,
        word: str,
        wrong_variants: List[str] = None,
        category: str = "general"
    ):
        """
        æ‰‹å‹•æ·»åŠ è©å½™

        Args:
            word: æ­£ç¢ºè©å½™
            wrong_variants: å¯èƒ½çš„éŒ¯èª¤è®Šé«”
            category: é¡åˆ¥
        """
        if word in self.vocabulary:
            entry = self.vocabulary[word]
            if wrong_variants:
                entry.wrong_variants.extend(
                    [v for v in wrong_variants if v not in entry.wrong_variants]
                )
            entry.frequency += 1
        else:
            self.vocabulary[word] = VocabularyEntry(
                correct_word=word,
                wrong_variants=wrong_variants or [],
                frequency=1,
                category=category,
                last_used=datetime.now().isoformat(),
                user_added=True
            )

        self._save_data()
        logger.info(f"â• æ·»åŠ è©å½™: '{word}'")

    def remove_vocabulary(self, word: str):
        """ç§»é™¤è©å½™"""
        if word in self.vocabulary:
            del self.vocabulary[word]
            self._save_data()
            logger.info(f"â– ç§»é™¤è©å½™: '{word}'")

    def get_vocabulary_list(self) -> List[Dict]:
        """ç²å–æ‰€æœ‰è©å½™åˆ—è¡¨"""
        return [
            {
                "word": entry.correct_word,
                "variants": entry.wrong_variants,
                "frequency": entry.frequency,
                "category": entry.category
            }
            for entry in sorted(
                self.vocabulary.values(),
                key=lambda x: x.frequency,
                reverse=True
            )
        ]

    def get_statistics(self) -> Dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        if not self.vocabulary:
            return {
                "total_words": 0,
                "total_corrections": 0,
                "average_confidence": 0.0,
                "categories": {}
            }

        # é¡åˆ¥çµ±è¨ˆ
        categories = Counter(entry.category for entry in self.vocabulary.values())

        # ç¸½ä¿®æ­£æ¬¡æ•¸
        total_corrections = sum(entry.frequency for entry in self.vocabulary.values())

        # è¨ˆç®—å¹³å‡ä¿¡å¿ƒåº¦ï¼ˆåŸºæ–¼ä½¿ç”¨é »ç‡ï¼‰
        total_freq = total_corrections
        avg_confidence = min(1.0, total_freq / (len(self.vocabulary) * 5)) if self.vocabulary else 0

        return {
            "total_words": len(self.vocabulary),
            "total_corrections": total_corrections,
            "average_confidence": avg_confidence,
            "categories": dict(categories),
            "top_words": [
                entry.correct_word
                for entry in sorted(
                    self.vocabulary.values(),
                    key=lambda x: x.frequency,
                    reverse=True
                )[:10]
            ]
        }

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰è©å½™å’Œæ­·å²è¨˜éŒ„"""
        self.vocabulary.clear()
        self.corrections_history.clear()
        self._save_data()
        logger.info("ğŸ—‘ï¸ å·²æ¸…ç©ºç”¨æˆ¶è©å½™åº«")

    # ==================== æ‰¹é‡å°å…¥/å°å‡º ====================

    def export_vocabulary(self, output_path: str):
        """å°å‡ºè©å½™åº«åˆ° JSON"""
        vocab_list = self.get_vocabulary_list()
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(vocab_list, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“¤ å°å‡º {len(vocab_list)} å€‹è©å½™åˆ° {output_path}")

    def import_vocabulary(self, input_path: str, merge: bool = True):
        """
        å¾ JSON å°å…¥è©å½™åº«

        Args:
            input_path: JSON æ–‡ä»¶è·¯å¾‘
            merge: æ˜¯å¦åˆä½µï¼ˆå¦å‰‡è¦†è“‹ï¼‰
        """
        with open(input_path, 'r', encoding='utf-8') as f:
            vocab_list = json.load(f)

        if not merge:
            self.vocabulary.clear()

        for item in vocab_list:
            word = item.get('word', '')
            if word:
                self.add_vocabulary(
                    word,
                    wrong_variants=item.get('variants', []),
                    category=item.get('category', 'general')
                )

        self._save_data()
        logger.info(f"ğŸ“¥ å°å…¥ {len(vocab_list)} å€‹è©å½™")


# ==================== ä¾¿åˆ©å‡½æ•¸ ====================

_learner_instance: Optional[VocabularyLearner] = None


def get_vocabulary_learner() -> VocabularyLearner:
    """ç²å–å…¨å±€è©å½™å­¸ç¿’å™¨å¯¦ä¾‹"""
    global _learner_instance
    if _learner_instance is None:
        _learner_instance = VocabularyLearner()
    return _learner_instance


def learn_correction(original: str, corrected: str, category: str = "general"):
    """å¿«æ·æ–¹æ³•ï¼šå­¸ç¿’ä¸€å€‹ä¿®æ­£"""
    learner = get_vocabulary_learner()
    learner.learn_from_correction(original, corrected, category=category)


def auto_correct_text(text: str) -> str:
    """å¿«æ·æ–¹æ³•ï¼šè‡ªå‹•æ ¡æ­£æ–‡æœ¬"""
    learner = get_vocabulary_learner()
    return learner.auto_correct(text)


def get_whisper_prompt() -> str:
    """å¿«æ·æ–¹æ³•ï¼šç²å– Whisper prompt"""
    learner = get_vocabulary_learner()
    return learner.generate_whisper_prompt()
